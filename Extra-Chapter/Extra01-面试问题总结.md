# LLM & VLM & Agent 面试问题总结

本文档是在备战2025秋招过程中整理的面试“八股”合集。

楼主主要投递的岗位包括：大模型算法工程师、Agent工程师、AI开发工程师、算法评测工程师等，面试公司以国内互联网中大厂为主。因此，本文档中的问题深度和广度都围绕这些岗位的要求展开，内容涵盖了从 LLM/VLM 核心理论，到 RAG/Agent 应用开发，再到 RLHF 对齐技术和模型/Agent 评估等全链路技术栈。所有问题均整理自多次线上技术面试的真实经历。

【使用建议】
本文档仅供学习与参考。为了达到最佳效果，强烈建议先独立思考每个问题，尝试构建自己的答案，然后再对照文档提供的参考思路进行查漏补缺。知其然，更要知其所以然。直接背诵是效率最低的方式。

预祝各位求职顺利，都能拿到心仪的Offer！

---

### 1. LLM 八股

1.  请详细解释一下 Transformer 模型中的自注意力机制是如何工作的？它为什么比 RNN 更适合处理长序列？
2.  什么是位置编码？在 Transformer 中，为什么它是必需的？请列举至少两种实现方式。
3.  请你详细介绍ROPE，对比绝对位置编码它的优劣势分别是什么？
4.  你知道MHA，MQA，GQA的区别吗？详细解释一下。
5.  请比较一下几种常见的 LLM 架构，例如 Encoder-Only, Decoder-Only, 和 Encoder-Decoder，并说明它们各自最擅长的任务类型。
6.  什么是Scaling Laws？它揭示了模型性能、计算量和数据量之间的什么关系？这对LLM的研发有什么指导意义？
7.  在LLM的推理阶段，有哪些常见的解码策略？请解释 Greedy Search, Beam Search, Top-K Sampling 和 Nucleus Sampling (Top-P) 的原理和优缺点。
8.  什么是词元化？请比较一下 BPE 和 WordPiece 这两种主流的子词切分算法。
9.  你觉得NLP和LLM最大的区别是什么？两者有何共同和不同之处？
10. L1和L2正则化分别是什么，什么场景适合使用呢？
11. “涌现能力”是大型模型中一个备受关注的现象，请问你如何理解这个概念？它通常在模型规模达到什么程度时出现？
12. 激活函数有了解吗，你知道哪些LLM常用的激活函数？为什么选用它？
13. 混合专家模型（MoE）是如何在不显著增加推理成本的情况下，有效扩大模型参数规模的？请简述其工作原理。
14. 在训练一个百或千亿参数级别的 LLM 时，你会面临哪些主要的工程和算法挑战？（例如：显存、通信、训练不稳定性等）
15. 开源框架了解过哪些？Qwen，Deepseek的论文是否有研读过，说一下其中的创新点主要体现在哪？
16. 最近读过哪些LLM比较前沿的论文，聊一下它的相关方法，针对什么问题，提出了什么方法，对比实验有哪些？

---

### 2. VLM 八股

1.  多模态大模型（如 VLM）的核心挑战是什么？即如何实现不同模态信息（如视觉和语言）的有效对齐和融合？
2.  请解释 CLIP 模型的工作原理。它是如何通过对比学习来连接图像和文本的？
3.  像 LLaVA 或 MiniGPT-4 这样的模型是如何将一个预训练好的视觉编码器（Vision Encoder）和一个大语言模型（LLM）连接起来的？请描述其关键的架构设计。
4.  什么是视觉指令微调？为什么说它是让 VLM 具备良好对话和指令遵循能力的关键步骤？
5.  在处理视频等多模态数据时，相比于静态图片，VLM 需要额外解决哪些问题？（例如，如何表征时序信息？）
6.  请解释Grounding在 VLM 领域中的含义。我们如何评估一个 VLM 是否能将文本描述准确地对应到图片中的特定区域？
7.  请对比至少不同的 VLM 架构范式（如共享编码器 vs. 跨模态注意力融合），并分析它们的优劣。
8.  在 VLM 的应用中，如何处理高分辨率的输入图像？这会带来哪些计算和模型设计上的挑战？
9.  VLM 在生成内容时，同样会遇到“幻觉”（Hallucination）问题，但它的表现形式和纯文本 LLM 有何不同？请举例说明。
10. 除了图片描述和视觉问答（VQA），你还能列举出 VLM 的哪些前沿或具有潜力的应用方向？
11. 有没有做过VLM相关方面的微调？什么模型？

---

### 3. RLHF 八股

1.  和传统SFT相比，RLHF旨在解决语言模型中的哪些核心问题？为什么说SFT本身不足以实现我们期望的“对齐”目标？
2.  请详细阐述经典RLHF流程的三个核心阶段。在每个阶段，输入是什么，输出是什么，以及该阶段的关键目标是什么？
3.  在RM训练阶段，我们通常收集的是成对比较数据，而不是让人类标注者直接给回复打一个绝对分数。你认为这样做的主要优势和潜在的劣势分别是什么？
4.  奖励模型的设计至关重要。它的模型架构通常如何选择？它与我们最终要优化的LLM是什么关系？在训练奖励模型时，常用的损失函数是什么？请解释其背后的数学原理（例如，可以结合Bradley-Terry模型来解释）。
5.  在RLHF的第三阶段，PPO是最主流的强化学习算法。为什么选择PPO，而不是其他更简单的策略梯度算法（如REINFORCE）或者Q-learning系算法？PPO中的KL散度惩罚项起到了什么关键作用？
6.  如果在PPO训练过程中，KL散度惩罚项的系数 β 设置得过大或过小，分别会导致什么样的问题？你将如何通过实验和观察来调整这个超参数？
7.  什么是“奖励作弊/奖励黑客”（Reward Hacking）？请结合一个具体的LLM应用场景给出一个例子，并探讨几种可能的缓解策略。
8.  RLHF流程复杂且不稳定。近年来出现了一些替代方案，例如DPO。请解释DPO的核心思想，并比较它与传统RLHF（基于PPO）的主要区别和优势。
9.  想象一下，你训练完成的RLHF模型在离线评估中表现优异，奖励模型分数很高，但上线后用户反馈其回答变得越来越“模式化”、奉承、且缺乏信息量。你认为可能的原因是什么？你会从哪些方面着手分析和解决这个问题？
10. 你知道Deepseek的GRPO吗，它和PPO的主要区别是什么？优劣是什么？
11. GSPO和DAPO有听说过吗？他们和GRPO有什么区别？
12. 如何解决信用分配问题？token级别和seq级别的奖励有何不同？
13. 除了人类反馈，我们还可以利用AI自身的反馈来做对齐，即RLAIF。请谈谈你对RLAIF的理解，它的潜力和风险分别是什么？

---

### 4. Agent

1.  你如何定义一个基于 LLM 的智能体（Agent）？它通常由哪些核心组件构成？
2.  请详细解释 ReAct 框架。它是如何将思维链和行动结合起来，以完成复杂任务的？
3.  在 Agent 的设计中，“规划能力”至关重要。请谈谈目前有哪些主流方法可以赋予 LLM 规划能力？（例如 CoT, ToT, GoT等）
4.  Memory是 Agent 的一个关键模块。请问如何为 Agent 设计短期记忆和长期记忆系统？可以借助哪些外部工具或技术？
5.  Tool Use是扩展 Agent 能力的有效途径。请解释 LLM 是如何学会调用外部 API 或工具的？（可以从 Function Calling 的角度解释）
6.  请比较一下两个流行的 Agent 开发框架，如 LangChain 和 LlamaIndex。它们的核心应用场景有何不同？
7.  在构建一个复杂的 Agent 时，你认为最主要的挑战是什么？
8.  什么是多智能体系统？让多个 LLM Agent 协同工作相比于单个 Agent 有什么优势？又会引入哪些新的复杂性？
9.  当一个 Agent 需要在真实或模拟环境中（如机器人、游戏）执行任务时，它与纯粹基于软件工具的 Agent 有什么本质区别？
10. 如何确保一个 Agent 的行为是安全、可控且符合人类意图的？在 Agent 的设计中，有哪些保障对齐方法？
11. 了解A2A框架吗？它和普通Agent框架的区别在哪，挑一个最关键的不同点说明。
12. 你用过哪些Agent框架？选型是如何选的？你最终场景的评价指标是什么？
13. 有微调过Agent能力吗？数据集如何收集？

---

### 5. RAG

1.  请解释 RAG 的工作原理。与直接对 LLM 进行微调相比，RAG 主要解决了什么问题？有哪些优势？
2.  一个完整的 RAG 流水线包含哪些关键步骤？请从数据准备到最终生成，详细描述整个过程。
3.  在构建知识库时，文本切块策略至关重要。你会如何选择合适的切块大小和重叠长度？这背后有什么权衡？
4.  如何选择一个合适的嵌入模型？评估一个 Embedding 模型的好坏有哪些指标？
5.  除了基础的向量检索，你还知道哪些可以提升 RAG 检索质量的技术？
6.  请解释“Lost in the Middle”问题。它描述了 RAG 中的什么现象？有什么方法可以缓解这个问题？
7.  如何全面地评估一个 RAG 系统的性能？请分别从检索和生成两个阶段提出评估指标。
8.  在什么场景下，你会选择使用图数据库或知识图谱来增强或替代传统的向量数据库检索？
9.  传统的 RAG 流程是“先检索后生成”，你是否了解一些更复杂的 RAG 范式，比如在生成过程中进行多次检索或自适应检索？
10. RAG 系统在实际部署中可能面临哪些挑战？
11. 了解搜索系统吗？和RAG有什么区别？
12. 知道或者使用过哪些开源RAG框架比如Ragflow？如何选择合适场景？

---

### 6. 模型评估与 Agent 评估

1.  为什么传统的 NLP 评估指标（如 BLEU, ROUGE）对于评估现代 LLM 的生成质量来说，存在很大的局限性？
2.  请介绍几个目前行业内广泛使用的 LLM 综合性基准测试，并说明它们各自的侧重点。（例如：MMLU, Big-Bench, HumanEval）
3.  什么是“LLM-as-a-Judge”？使用 LLM 来评估另一个 LLM 的输出，有哪些优点和潜在的偏见？
4.  如何设计一个评估方案来衡量 LLM 的特定能力，比如“事实性/幻觉水平”、“推理能力”或“安全性”？
5.  评估一个 Agent 为什么比评估一个基础 LLM 更加困难和复杂？评估的维度有哪些不同？
6.  你了解哪些专门用于评估 Agent 能力的基准测试？这些基准通常如何构建测试环境和任务？
7.  在评估一个 Agent 的任务完成情况时，除了最终结果的正确性，还有哪些过程指标是值得关注的？（例如：效率、成本、鲁棒性）
8.  什么是红队测试？它在发现 LLM 和 Agent 的安全漏洞与偏见方面扮演着什么角色？
9.  在进行人工评估时，如何设计合理的评估准则和流程，以保证评估结果的客观性和一致性？
10. 如何持续监控和评估一个已经部署上线的 LLM 应用或 Agent 服务的表现，以应对可能出现的性能衰退或行为漂移？

---

### 7. LLM 前景与发展

1.  你认为当前 LLM 距离通用人工智能（AGI）还有多远？最关键的缺失能力是什么？
2.  从 GPT-4 到未来的模型，你认为多模态的融合会走向何方？仅仅是文本、图像的结合，还是会拓展到更多感官维度？
3.  你如何看待开源模型和闭源模型生态系统的竞争与共存？它们各自的优势是什么，未来将如何演进？
4.  随着模型能力的增强，LLM 的“世界模型”或内在模拟能力也备受关注。你如何理解这个概念？它对实现更高阶的推理和规划有何意义？
5.  “数据”是训练 LLM 的燃料。你认为高质量的人工合成数据在未来的模型训练中将扮演什么样的角色？
6.  具身智能（Embodied AI），即 LLM 与机器人的结合，被认为是 AI 的下一个浪潮。你认为 LLM 将如何赋能机器人，并会带来哪些挑战？
7.  个性化是 LLM 应用的重要方向。在实现高度个性化的 Agent 或助手的过程中，我们应如何平衡效果、隐私和安全？
8.  你认为 Transformer 架构会长久地统治这个领域吗？还是你看到了像状态空间模型（SSM, 如 Mamba）等新架构的潜力？
9.  展望未来 3-5 年，你认为 LLM 和 Agent 技术最有可能在哪个行业或领域率先实现颠覆性的应用？为什么？

---

### 8. 其它

1.  你认为目前限制Agent能力和普及的最大瓶颈是什么？（例如：模型能力、成本、可靠性、还是其他？）
2.  在过去半年里，哪一篇关于Agent的论文或哪一个开源项目让你印象最深刻？为什么？
3.  你如何看待Agent领域的“涌现能力”？我们应该追求更强大的基础模型，还是更精巧的Agent架构？
4.  你认为未来1-2年内，Agent技术最有可能在哪个行业或场景率先实现大规模商业落地？
5.  如果让你自由探索，你最想创造一个什么样的Agent来解决什么问题？
6.  对于想要进入Agent领域的初学者，你会给他/她什么建议？应该重点学习哪些技术？
7.  总结一下，你认为一个顶尖的AI Agent工程师，应该具备哪些核心素质？
8.  平常使用AI吗，都用来干嘛？如果我想使用AI，比如coding领域，你有何建议给我？