# 第五章 基于低代码平台的智能体搭建

在前一章中，通过编写 Python 代码，从零开始实现了 ReAct、Plan-and-Solve 和 Reflection 多种经典的智能体工作流。这个过程为我们打下了坚实的技术基础，让我们深刻理解了智能体内部的运作机理。然而，对于一个快速发展的领域而言，纯代码的开发模式并非总是最高效的选择，尤其是在需要快速验证想法、或者非专业开发者希望参与构建的场景中。

## 5.1 平台化构建的兴起

随着技术的成熟，我们看到越来越多的能力正在被“平台化”。正如网站的开发从手写 HTML/CSS/JS，演进到了可以使用 WordPress、Wix 等建站平台一样，智能体的构建也迎来了平台化的浪潮。本章将聚焦于如何利用图形化、模块化的低代码平台，来快速、直观地搭建、调试和部署智能体应用，将我们的重心从“实现细节”转向“业务逻辑”。

### 5.1.1 为何需要低代码平台

“重复造轮子”对于深入学习至关重要，但在追求工程效率和创新的实战中，我们往往需要站在巨人的肩膀上。尽管我们在第四章中封装了可复用的 `ReActAgent`、`PlanAndSolveAgent` 等类，但当业务逻辑变得复杂时，纯代码的维护成本和开发周期会急剧上升。低代码平台的出现，正是为了解决这些痛点。

其核心价值主要体现在以下几个方面：

1. <strong>降低技术门槛</strong>：低代码平台将复杂的技术细节（如 API 调用、状态管理、并发控制）封装成一个个易于理解的“节点”或“模块”。用户无需精通编程，只需通过拖拽、连接这些节点，就能构建出功能强大的工作流。这使得产品经理、设计师、业务专家等非技术人员也能参与到智能体的设计与创造中来，极大地拓宽了创新的边界。
2. <strong>提升开发效率：对于专业开发者而言，平台同样能带来巨大的效率提升。在项目初期，当需要快速验证一个想法或搭建一个原型 (Prototype) 时，使用低代码平台可以在数小时甚至数分钟内完成原本需要数天编码的工作。开发者可以将精力更多地投入到业务逻辑梳理和提示工程优化上，而非底层的工程实现。
3. </strong>提供更优的可视化与可观测性<strong>：相比于在终端中打印日志，图形化的平台天然提供了对智能体运行轨迹的端到端可视化。你可以清晰地看到数据在每一个节点之间如何流动，哪一个环节耗时最长，哪一个工具调用失败。这种直观的调试体验，是纯代码开发难以比拟的。
4. </strong>标准化与最佳实践沉淀<strong>：优秀的低代码平台通常会内置许多行业内的最佳实践。例如，它会提供预设的 ReAct 模板、优化的知识库检索引擎、标准化的工具接入规范等。这不仅避免了开发者“踩坑”，也使得团队协作更加顺畅，因为所有人都基于同一套标准和组件进行开发。

简而言之，低代码平台并非要取代代码，而是提供了一种更高层次的抽象。它让我们可以从繁琐的底层实现中解放出来，更专注于智能体“思考”与“行动”的逻辑本身，从而更快、更好地将创意变为现实。

### 5.1.2 低代码平台的选择

当前，智能体与 LLM 应用的低代码平台市场呈现出百花齐放的态势，每个平台都有其独特的定位和优势。选择哪个平台，往往取决于你的核心需求、技术背景以及项目的最终目标。在本章的后续内容中，我们将重点介绍并实操四个各具代表性的平台：Coze、Dify、FastGPT 和 n8n。在此之前，我们先对它们进行一个概要性的介绍。

</strong>Coze<strong>

- </strong>核心定位<strong>：由字节跳动推出的 Coze，主打零代码/低代码的 Agent 的构建体验，让不具备编程背景的用户也能轻松创造。
- </strong>特点分析<strong>：Coze 拥有极其友好的可视化界面，用户可以像搭建乐高积木一样，通过拖拽插件、配置知识库和设定工作流来创建智能体。其内置了极为丰富的插件库，并支持一键发布到抖音、飞书、微信公众号等多个主流平台，极大地简化了分发流程。
- </strong>适用人群<strong>：AI 应用的入门用户、产品经理、运营人员，以及希望快速将创意变为可交互产品的个人创作者。

</strong>Dify<strong>

- </strong>核心定位<strong>：Dify 是一个开源的、功能全面的 LLM 应用开发与运营平台，旨在为开发者提供从原型构建到生产部署的一站式解决方案。
- </strong>特点分析<strong>：它融合了后端服务和模型运营的理念，支持 Agent 工作流、RAG Pipeline、数据标注与微调等多种能力。对于追求专业、稳定、可扩展的企业级应用而言，Dify 提供了坚实的基础。
- </strong>适用人群<strong>：有一定技术背景的开发者、需要构建可扩展的企业级 AI 应用的团队。

</strong>FastGPT<strong>

- </strong>核心定位<strong>：FastGPT 是一个专注于知识库问答场景的开源 AI 平台。

- </strong>特点分析<strong>：它的核心优势在于强大的</strong>检索增强生成（Retrieval-augmented generation, RAG）<strong>能力。用户可以轻松导入多种格式的私有文档，快速构建一个高质量、高精度的企业知识库或智能客服。相比于 Dify，FastGPT 更轻量、在 RAG 效果上打磨得更深，并提供了与 OpenAI 兼容的 API，便于集成。

- </strong>适用人群<strong>：需要构建企业内部知识库、AI 客服、领域知识问答系统的开发者或中小企业。

</strong>n8n<strong>

- </strong>核心定位<strong>：n8n 本质上是一个开源工作流自动化工具，而非纯粹的 LLM 平台。近年来，它积极集成了 AI 能力。

- </strong>特点分析<strong>：n8n 的强项在于“连接”。它拥有数百个预置的节点，可以轻松地将各类 SaaS 服务、数据库、API 连接成复杂的自动化业务流程。你可以在这个流程中嵌入 LLM 节点，使其成为整个自动化链路中的一环。虽然在 LLM 功能的专一度上不如前三者，但其通用自动化能力是独一无二的。不过，其学习曲线也相对陡峭。

- </strong>适用人群<strong>：需要将 AI 能力深度整合进现有业务流程、实现高度定制化自动化的开发者和企业。

在接下来的小节中，我们将逐一上手体验这些平台，通过实际操作来更直观地感受它们各自的魅力。

## 5.2 平台一：Coze

### 5.2.1 Coze 的功能模块与集成能力

### 5.2.2 构建集成多种工具的“每日简报”智能体

案例说明: 这个实践将展示 Coze 强大的插件集成能力。我们将创建一个能生成“每日简报”的助理，它能自动查询当天的天气、抓取最新的AI领域头条新闻，并将这些信息整合成一段结构化的摘要。

#### 5.2.2.1 步骤一：设定智能体角色与提示词

#### 5.2.2.2 步骤二：添加并配置插件（新闻、天气）

#### 5.2.2.3 步骤三：测试、调试与多渠道发布

### 5.2.3 Coze 的优势与局限性分析

## 5.3 平台二：Dify
### 5.3.1 Dify 的架构与特性
### 5.3.2 构建 Hello Agents 专属问答智能体
案例说明: 这个实践的目标是利用 Dify 强大的知识库功能，将这个项目的前四章作为知识源，创建一个能精准回答本书内容的智能问答助手。
#### 5.3.2.1 步骤一：创建并配置知识库
#### 5.3.2.2 步骤二：设计系统提示词与对话流程
#### 5.3.2.3 步骤三：调试与效果验证
### 5.3.3 Dify 的优势与局限性分析



## 5.4 平台三：FastGPT

### 5.4.1 FastGPT 的知识库与工作流引擎

### 5.4.2 构建一个企业级私有知识库问答机器人

#### 5.4.2.1 步骤一：数据处理与知识库构建

#### 5.4.2.2 步骤二：设计高级问答流程（工作流）

#### 5.4.2.3 步骤三：API 对接与多渠道发布

### 5.4.3 FastGPT 的优势与局限性分析



## 5.5 平台四：n8n

正如我们之前所介绍的，n8n 的核心身份是一个通用的工作流自动化平台，而非一个纯粹的 LLM 应用构建工具。理解这一点，是掌握 n8n 的关键。在使用 n8n 构建智能应用时，我们实际上是在设计一个更宏大的自动化流程，而大语言模型只是这个流程中的一个（或多个）强大的“处理节点”。

### 5.5.1 n8n 的节点与工作流

n8n 的世界由两个最基本的概念构成：</strong>节点 (Node)<strong> 和 </strong>工作流 (Workflow)<strong>。

- </strong>节点 (Node)<strong>：节点是工作流中执行具体操作的最小单元。你可以把它想象成一个具有特定功能的“积木块”。n8n 提供了数百种预置节点，涵盖了从发送邮件、读写数据库、调用 API 到处理文件等各种常见操作。每个节点都有输入和输出，并提供图形化的配置界面。节点大致可以分为两类：
  - </strong>触发节点 (Trigger Node)<strong>：它是整个工作流的起点，负责启动流程。例如，“当收到一封新的 Gmail 邮件时”、“每小时定时触发一次”或“当接收到一个 Webhook 请求时”。一个工作流必须有且仅有一个触发节点。
  - </strong>常规节点 (Regular Node)<strong>：负责处理具体的数据和逻辑。例如，“读取 Google Sheets 表格”、“调用 OpenAI 模型”或“在数据库中插入一条记录”。
- </strong>工作流 (Workflow)<strong>：工作流是由多个节点连接而成的自动化流程图。它定义了数据从触发节点开始，如何一步步地在不同节点之间传递、被处理，并最终完成预设任务的完整路径。数据在节点之间以结构化的 JSON 格式进行传递，这使得我们可以精确地控制每一个环节的输入和输出。


n8n 的真正威力在于其强大的“连接”能力。它可以将原本孤立的应用程序和服务（如企业内部的 CRM、外部的社交媒体平台、你的数据库以及大语言模型）串联起来，实现过去需要复杂编码才能完成的端到端业务流程自动化。在接下来的实战中，我们将亲手体验如何利用这套节点和工作流系统，构建一个集成了 AI 能力的自动化应用。

### 5.5.2 搭建智能邮件助手

关于n8n的环境配置和最基础的使用，在项目的`Add-Chapter`文件夹下制作了文档，这里就不过多介绍。在上一节中，我们了解了 n8n 的基本概念。这个案例将清晰地展示现代 AI Agent 与传统自动化工作流的核心区别。传统流程是线性的，而我们即将构建的 Agent 将能够接收用户邮件，通过一个核心的 </strong>AI Agent 节点<strong> 进行“思考”，自主理解用户意图，并在多个可用“工具”中进行决策和选择，最终自动生成并发送高度相关的回复。

整个过程模拟了一个更高级的决策逻辑：`接收 -> AI Agent (思考 -> 决策 -> 工具调用) -> 回复`。

<div align="center">
  <img src="https://raw.githubusercontent.com/datawhalechina/Hello-Agents/main/docs/images/5-figures/n8n-01.png" alt="图片描述" width="90%"/>
  <p>图 5.X 一体化智能邮件 Agent 架构示意图</p>
</div>

与将工具拆分为多个子工作流的传统方法不同，n8n 的 `AI Agent` 节点允许我们将组件，例如大语言模型（LLM）、记忆（Memory）、工具（Tools）都整合在一个统一的界面中，极大地简化了构建过程。

整个搭建过程分为两个核心步骤：

1. </strong>准备 Agent 的“记忆”<strong>：创建一个独立的流程，为 Agent 加载私有知识库。
2. </strong>构建 Agent 主体<strong>：创建接收邮件、思考并回复的主工作流。

### 5.5.3 构建 Agent 的私有知识库

为了让 Agent 能够回答关于特定领域（比如您的个人信息或项目文档）的问题，我们需要先为它准备一个“外部大脑”，一个向量知识库。

在 n8n 中，我们可以使用 `Simple Vector Store` 节点在内存中快速构建一个知识库。这个准备流程通常只需要在更新知识时运行一次。

</strong>(1) 定义知识源<strong>

首先，我们使用 `Code` 节点来存放我们的原始知识文本。这是一个简单快捷的方式，实际项目中数据也可以来自文件、数据库等。

- </strong>节点<strong>：`Code`
- </strong>内容<strong>：将您的知识以 JSON 格式写入。

<div align="center">
  <img src="https://raw.githubusercontent.com/datawhalechina/Hello-Agents/main/docs/images/5-figures/n8n-02.png" alt="Code 节点中填写了知识库 JSON 文本的截图" width="90%"/>
  <p>图 5.X 在 Code 节点中定义知识源</p>
</div>

```javascript
return [
  {
    "doc_id": "work-schedule-001",
    "content": "我的工作时间是周一至周五，上午9点到下午5点。时区是澳大利亚东部标准时间（AEST）。"
  },
  {
    "doc_id": "off-hours-policy-001",
    "content": "在非工作时间（包括周末和公共假期），我无法立即回复邮件。"
  },
  {
    "doc_id": "auto-reply-instruction-001",
    "content": "如果邮件是在非工作时间收到的，AI助手应该告知发件人，邮件已收到，我会在下一个工作日的9点到5点之间尽快处理并回复。"
  }
];
```

</strong>(2) 文本向量化 (Embeddings)<strong>

计算机无法直接理解文本，需要将其转换为向量。我们使用 `Embeddings` 节点来完成这个“翻译”工作。

- </strong>节点<strong>：`Embeddings Google Gemini`，选择模型为`gemini-embedding-exp-03-07`。这里使用Google API来演示，如果不知道如何获取Google API可以参考5.5.3小节。
- </strong>配置<strong>：将其连接到 `Code` 节点之后，它会自动将上游传入的文本转换为向量数据。

<div align="center">
  <img src="https://raw.githubusercontent.com/datawhalechina/Hello-Agents/main/docs/images/5-figures/n8n-03.png" alt="" width="90%"/>
  <p>图 5.X 对 Code 中数据进行向量化</p>
</div>

</strong>(3) 存入向量存储<strong>

最后，我们将向量化的知识存入内存数据库中。

- </strong>节点<strong>：`Simple Vector Store`
- </strong>配置<strong>:
  - </strong>Operation Mode<strong>: `Insert Documents` (写入模式)。
  - </strong>Memory Key<strong>: 为这个知识库起一个唯一的名字，例如 `my-dailytime`。这个 Key 相当于数据库的“表名”，后续 Agent 将通过它来查找信息。

<div align="center">
  <img src="https://raw.githubusercontent.com/datawhalechina/Hello-Agents/main/docs/images/5-figures/n8n-04.png" alt="" width="90%"/>
  <p>图 5.X 对 Code 中数据存入向量存储</p>
</div>

完成配置后，</strong>手动执行一次<strong>这个流程。成功后，您的私有知识就加载到 n8n 的内存中了。

<div align="center">
  <img src="https://raw.githubusercontent.com/datawhalechina/Hello-Agents/main/docs/images/5-figures/n8n-05.png" alt="" width="90%"/>
  <p>图 5.X 完整的知识库加载工作流</p>
</div>

### 5.5.4 创建 Agent 主工作流

有了工具，我们现在开始构建 Agent 的主要流程。它将负责接收邮件、进行思考和决策，并在合适的时机调用我们刚刚创建的工具，最终执行邮件的回复。

（1）配置 Gmail 触发器

新建一个工作流，命名为 `Agent: Customer Support`。使用 `Gmail` 节点作为触发器，将其 </strong>Event<strong> 设置为 `Message Received`，并配置好你的邮箱账号。这样，每当有新邮件进入收件箱时，该工作流就会被自动触发。

<div align="center">
  <img src="https://raw.githubusercontent.com/datawhalechina/Hello-Agents/main/docs/images/5-figures/n8n-06.png" alt="" width="90%"/>
  <p>图 5.X 新建Gmail节点图</p>
</div>

配置过程可参考[n8n官方文档](https://docs.n8n.io/integrations/builtin/credentials/google/oauth-single-service/?utm_source=n8n_app&utm_medium=credential_settings&utm_campaign=create_new_credentials_modal#enable-apis)。Gmail的api在这里[配置](https://console.cloud.google.com/apis/library/gmail.googleapis.com?project=apt-entropy-471905-b9)，需要创建凭证，选择Web 应用类型，最后即得到所需的客户端ID和客户端密钥。并且需要在已获授权的重定向 URI 将n8n刚给的OAuth Redirect URL给添加上。同时，还需要在[目标对象](https://console.cloud.google.com/auth/audience?project=apt-entropy-471905-b9)的Add users加上自己的邮箱地址。最终配置完成的页面如图5.X所示。

<div align="center">
  <img src="https://raw.githubusercontent.com/datawhalechina/Hello-Agents/main/docs/images/5-figures/n8n-07.png" alt="" width="90%"/>
  <p>图 5.X Gmail账号加载成功图</p>
</div>

现在我们可以点击`Fetch Test Event`获取邮件了！

<div align="center">
  <img src="https://raw.githubusercontent.com/datawhalechina/Hello-Agents/main/docs/images/5-figures/n8n-08.png" alt="" width="90%"/>
  <p>图 5.X 获取实时邮件图</p>
</div>

（2）配置 AI Agent 节点

这是整个工作流的大脑。从节点菜单中拖出一个 `AI Agent` 节点，并进行如下配置：

- </strong>Chat Model<strong>: 连接您选择的大语言模型，例如 `Google Gemini Chat Model`。这是 Agent 的“思考核心”。
- </strong>Memory<strong>: 连接一个 `Simple Memory` 节点。这能让 Agent 在处理同一邮件线索下的多封往来邮件时，记住之前的对话历史。
- </strong>Tools<strong>: 我们可以将多个工具连接到这里。在我们的案例中，我们连接两个工具：
  1. `SerpAPI`: 这是我们之前第四章案例中使用过的API，让 Agent 拥有上网搜索公开信息的能力。
  2. `Simple Vector Store`: 让 Agent 拥有查询我们第一部分中创建的私有知识库的能力。

<div align="center">
  <img src="https://raw.githubusercontent.com/datawhalechina/Hello-Agents/main/docs/images/5-figures/n8n-09.png" alt="" width="90%"/>
  <p>图 5.X AI Agent节点设置图</p>
</div>

这是 Agent “思考”的第一步。添加一个 `Gemini` 节点（或其他 LLM 节点），模式设置为 `Chat`。我们的目标是让它分析邮件内容，判断用户意图。Prompt 的设计至关重要，一个清晰的指令能让 LLM 更准确地完成任务。我们将邮件正文和主题（`{{ $json.snippet }}{{ $json.Subject }}`）作为变量传入 Prompt 中，没有API可以到[Google AI Studio](https://aistudio.google.com/prompts/new_chat)点击Get API key创建一个可用的。

其中，对于AI Agent节点，我们需要填的主要是`User Message`和`System Message`部分。

<div align="center">
  <img src="https://raw.githubusercontent.com/datawhalechina/Hello-Agents/main/docs/images/5-figures/n8n-10.png" alt="" width="90%"/>
  <p>图 5.X AI Agent 节点详解图</p>
</div>

在这里给出我们案例所使用的Prompt：

```json
# Prompt (User Message)
# 上下文信息
- 当前时间: {{ new Date().toLocaleString('en-AU', { timeZone: 'Australia/Sydney', hour12: false }) }} (澳大利亚悉尼时间)
- 发件人: {{ $json.From }}
- 主题: {{ $json.Subject }}
- 邮件正文: {{ $json.snippet }}

# System Message
# 角色和目标
你是一个全天候待命、专业高效的AI邮件助手。你的任务是：第一时间使用公开信息尽力回答所有邮件中的问题，并根据我的工作日程，在回复的开头附加上下文状态提醒。

# 上下文信息
- 当前时间: {{ new Date().toLocaleString('en-AU', { timeZone: 'Australia/Sydney', hour12: false }) }} (澳大利亚悉尼时间)
- 邮件信息在输入数据中。

# 可用工具
- Simple Vector Store2: 用来查询我准确的工作时间（例如：周一至周五，上午9点到下午5点）。
- SerpAPI: </strong>[主要信息来源]<strong> 优先使用此工具在互联网上搜索，以回答邮件中的具体问题。

# 执行步骤
1.  </strong>分析问题<strong>: 首先，仔细阅读邮件内容，提炼出发件人的核心问题。

2.  </strong>并行信息搜集<strong>: 同时执行以下两个操作来收集信息：
    a. 使用 `SerpAPI` 工具，上网搜索出发件人问题的答案。
    b. 使用 `Simple Vector Store2` 工具，获取我设定的准确工作时间。

3.  </strong>草拟核心回复<strong>: 根据 `SerpAPI` 搜集到的信息，清晰、直接地回答发件人的问题，这部分将作为邮件回复的主体。

4.  </strong>添加状态前缀并整合<strong>:
    a. 对比“当前时间”和我从工具中获取的工作时间。
    b. </strong>如果当前是“非工作时间”<strong>: 创建一段状态提醒前缀。这段前缀</strong>必须包含**从 `Simple Vector Store2` 获取到的具体工作时间。
        * <strong>前缀示例</strong>: "您好，感谢您的来信。您已在我的非工作时间联系我（我的工作时间为：[此处插入查询到的工作时间]）。我会在下一个工作日亲自审阅此邮件。与此同时，这是根据公开信息为您找到的初步答复：<strong><br><br>---<br><br></strong>"
    c. <strong>如果当前是“工作时间”</strong>: 只需使用简单的问候语即可。
        * <strong>前缀示例</strong>: "您好，关于您提出的问题，答复如下：<strong><br><br>---<br><br></strong>"
    d. 将生成的前缀和你草拟的核心回复（第3步的结果）拼接在一起，形成最终的邮件正文。

5.  <strong>格式化输出</strong>: 你必须将最终生成的邮件内容以一个严格的 JSON 格式输出。格式如下，不要添加任何额外的解释或文字：
    {
      "shouldReply": true,
      "subject": "Re: [原始邮件主题]",
      "body": "[这里是拼接好的、完整的邮件回复正文，<strong>所有换行必须使用HTML的<br>标签</strong>]"
    }

# 规则和限制
- <strong>永远优先尝试回答</strong>: 无论何时，你的首要任务是使用 `SerpAPI` 为用户提供有价值的回复。
- <strong>必须声明状态</strong>: 如果在非工作时间回复，必须在邮件开头明确声明，并附上我准确的工作时间。
- <strong>信息来源要准确</strong>: 工作时间必须严格以 `Simple Vector Store2` 的结果为准；问题答案主要来源于 `SerpAPI`，不要编造信息。
- <strong>输出格式</strong>: <strong>在最终输出的JSON中，`body`字段内的所有换行都必须使用 `<br>` 标签，而不是 `\n`。</strong>
```

(3) 配置 Agent 的工具

对于 `Simple Vector Store` 工具，我们需要进行关键配置，以确保它能正确“读取”我们之前存入的知识：

- <strong>Operation Mode</strong>: `Retrieve Documents (As Tool for AI Agent)` (作为工具的读取模式)。
- <strong>Memory Key</strong>: 必须填写与第一部分<strong>完全相同</strong>的 Key，即 `my_private_knowledge`。
- <strong>Embeddings</strong>: 必须使用与第一部分<strong>完全相同</strong>的 `Embeddings Google Gemini` 模型。

只有 `Memory Key` 和 `Embeddings` 模型完全一致，Agent 才能用正确的“钥匙”和“语言”来访问知识库。

<div align="center">
  <img src="https://raw.githubusercontent.com/datawhalechina/Hello-Agents/main/docs/images/5-figures/n8n-11.png" alt="" width="90%"/>
  <p>图 5.X Simple Vector Store工具配置</p>
</div>

Description参数即AI Agent调用该工具时，对该工具的描述定义，在这里也给出对应的Prompt：

```json
这是Simple Vector Store2工具，用来查询我的个人信息，特别是我的工作时间和邮件回复策略。当需要判断当前是否为工作时间，或者需要告知对方我何时会回复邮件时，必须使用此工具。
```

对于Memory唯一需要注意的是，这里我们使用每个邮箱的线程名作为唯一标识，能保证存储的唯一性，设置的Key为`{{ $('Gmail').item.json.threadId }}`



(4) 发送最终回复

最后一步是执行。将 `AI Agent` 节点的输出连接到一个 `Gmail` 节点，<strong>Operation</strong> 设为 `Send`。使用 n8n 表达式，将收件人、主题和正文分别关联到 `AI Agent` 输出的 JSON 数据中的相应字段，即可实现邮件的自动回复。

- <strong>To</strong>: `{{ $('Gmail').item.json.From }}` (或其他触发器中的发件人字段)
- <strong>Subject</strong>: `Re:  {{ $('Gmail').item.json.Subject }}`
- <strong>Message</strong>: `{{ $json.output }}`

<div align="center">
  <img src="https://raw.githubusercontent.com/datawhalechina/Hello-Agents/main/docs/images/5-figures/n8n-12.png" alt="" width="90%"/>
  <p>图 5.X 最终回复工具图示</p>
</div>

并且发送成功的同时，也能在个人邮箱收到真实的返回邮件信息，如图5.X所示。

<div align="center">
  <img src="https://raw.githubusercontent.com/datawhalechina/Hello-Agents/main/docs/images/5-figures/n8n-13.png" alt="" width="90%"/>
  <p>图 5.X 个人邮箱返回邮件格式</p>
</div>

至此，一个基于 `AI Agent` 节点的一体化智能客服就构建完成了，你可以发送一封测试邮件来检验它的工作成果。这个架构的扩展性极强。未来，您可以直接向 `AI Agent` 节点添加更多的工具（如日历、数据库、CRM 等），只需在 Prompt 中教会 Agent 如何使用它们，就能不断赋予您的 Agent 更强大的能力。

### 5.5.3 n8n 的优势与局限性分析

通过前面从零到一构建智能邮件助手的实践，我们已经对 n8n 的工作模式有了直观的感受。作为一个强大的低代码自动化平台，n8n 在赋能 Agent 应用开发方面表现出色，但它也并非万能。如表5.X所示，我们将客观地分析其优势与潜在的局限性。

<div align="center">
  <p>表 5.X n8n 平台的优势与局限性总结</p>
  <img src="https://raw.githubusercontent.com/datawhalechina/Hello-Agents/main/docs/images/5-figures/n8n-14.png" alt="" width="90%"/>
</div>

首先，n8n 最显著的优势在于其<strong>开发效率</strong>。它将复杂的逻辑抽象为直观的可视化工作流，无论是邮件的接收、AI 的决策，还是工具的调用和最终的回复，整个数据流和处理链路都在画布上一目了然。这种低代码的特性极大地降低了技术门槛，让开发者能够快速搭建和验证 Agent 的核心逻辑，极大地缩短了从想法到原型的距离。

其次，平台的<strong>功能强大且高度集成</strong>。n8n 拥有丰富的内置节点库，可以轻松连接像 Gmail、Google Gemini 等数百种常见服务。更重要的是，其先进的 `AI Agent` 节点将模型、记忆和工具管理高度整合，让我们能用一个节点就实现复杂的自主决策，这比传统的多节点手动路由方式要优雅和强大得多。同时，对于内置功能无法覆盖的场景，`Code` 节点也提供了编写自定义代码的灵活性，保证了功能的上限。

最后，在<strong>部署运维</strong>层面，n8n 支持<strong>私有化部署</strong>，并且也是目前相对比较简单且能部署完整版项目的私有化Agent方案，这一点对于注重数据安全和隐私的企业至关重要。我们可以将整个服务部署在自己的服务器上，确保类似内部邮件、客户数据等敏感信息不离开自有环境，这为 Agent 应用的合规性提供了坚实的基础。

当然，每个工具都有其取舍。在享受 n8n 带来便利的同时，我们也必须认识到其局限性。

在<strong>开发效率</strong>的背后，是<strong>调试与错误处理的相对繁琐</strong>。当工作流变得复杂时，一旦出现数据格式错误，开发者可能需要逐个节点检查其输入输出来定位问题，这有时不如在代码中设置断点来得直接。

功能方面，最大的局限性体现在其<strong>内置存储的非持久性</strong>。我们在案例中使用的 `Simple Memory` 和 `Simple Vector Store` 都是基于内存的，这意味着 n8n 服务一旦重启，所有对话历史和知识库都将丢失。这对于生产环境的应用是致命的。因此，在实际部署时，必须将其替换为如 Redis、Pinecone 等外部持久化数据库，这也会增加了额外的配置和维护成本。

此外，在<strong>部署运维</strong>和团队协作上，n8n 的<strong>版本控制和多人协作不如传统代码成熟</strong>。虽然可以将工作流导出为 JSON 文件进行管理，但对比其变更远不如 `git diff` 代码来得清晰，多人同时编辑同一个工作流也容易产生冲突。

最后是关于<strong>性能</strong>，n8n 完全能满足绝大多数企业自动化和中低频次的 Agent 任务。但对于需要处理超高并发请求的场景，其节点调度机制可能会带来一定的性能开销，相比于纯代码实现的服务可能稍逊一筹。

## 5.6 本章小结

## 参考文献
[1]